{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_Sprint.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "yJ8fpByNCkCs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "e64e1788-f4f2-4e00-eb5c-08578004bdce",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531508876882,
          "user_tz": 0,
          "elapsed": 5483,
          "user": {
            "displayName": "Cassidy",
            "photoUrl": "//lh3.googleusercontent.com/-oPQKa7ZQ87U/AAAAAAAAAAI/AAAAAAAABPk/tTZ21OI6_LY/s50-c-k-no/photo.jpg",
            "userId": "104428058049649798597"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/50/ed4a03d2be47ffd043be2ee514f329ce45d98a30fe2d1b9c61dea5a9d861/gym-0.10.5.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.5)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.4.16)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/cb/14/71/f4ab006b1e6ff75c2b54985c2f98d0644fffe9c1dddc670925\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "Successfully installed gym-0.10.5 pyglet-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MQVupeaMDRxL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aln0wjzBDTtx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "46b76dd3-2414-4bb0-fc69-b2fb30b77330",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531515331912,
          "user_tz": 0,
          "elapsed": 331,
          "user": {
            "displayName": "Cassidy",
            "photoUrl": "//lh3.googleusercontent.com/-oPQKa7ZQ87U/AAAAAAAAAAI/AAAAAAAABPk/tTZ21OI6_LY/s50-c-k-no/photo.jpg",
            "userId": "104428058049649798597"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('Taxi-v2')\n",
        "state = env.reset()\n",
        "env.render()\n",
        "\n",
        "total_reward = 0\n",
        "done = False\n",
        "while not done:\n",
        "    state, reward, done, info = env.step(env.action_space.sample())\n",
        "    total_reward += reward\n",
        "    #env.render()\n",
        "\n",
        "print('Total reward:', total_reward)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "Total reward: -839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GFLh3pKFKiJC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hu8fr9dTK_ui",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('Taxi-v2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hF_5LaXPLG2x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "action_size = env.action_space.n\n",
        "state_size = env.observation_space.n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yo0sH2FYLLeF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7593c5b9-2daf-4e23-8ad7-dbb27e09d95d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531517051697,
          "user_tz": 0,
          "elapsed": 321,
          "user": {
            "displayName": "Cassidy",
            "photoUrl": "//lh3.googleusercontent.com/-oPQKa7ZQ87U/AAAAAAAAAAI/AAAAAAAABPk/tTZ21OI6_LY/s50-c-k-no/photo.jpg",
            "userId": "104428058049649798597"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "qtable = np.zeros((state_size, action_size))\n",
        "print(qtable)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5imayPmbhooN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ee0f48ed-1182-4cfc-a2b0-3fc49aea8134",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531517124151,
          "user_tz": 0,
          "elapsed": 248,
          "user": {
            "displayName": "Cassidy",
            "photoUrl": "//lh3.googleusercontent.com/-oPQKa7ZQ87U/AAAAAAAAAAI/AAAAAAAABPk/tTZ21OI6_LY/s50-c-k-no/photo.jpg",
            "userId": "104428058049649798597"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "\n",
        "# For plotting metrics\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "for i in range(1, 100001):\n",
        "    state = env.reset()\n",
        "\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample() # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(qtable[state]) # Exploit learned values\n",
        "\n",
        "        next_state, reward, done, info = env.step(action) \n",
        "        \n",
        "        old_value = qtable[state, action]\n",
        "        next_max = np.max(qtable[next_state])\n",
        "        \n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        qtable[state, action] = new_value\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "        \n",
        "    if i % 100 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Episode: {i}\")\n",
        "\n",
        "print(\"Training finished.\\n\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 100000\n",
            "Training finished.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3gCItfYnimru",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c7f2dea-29fc-428b-d30f-83c8a2075376",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531517282279,
          "user_tz": 0,
          "elapsed": 2015,
          "user": {
            "displayName": "Cassidy",
            "photoUrl": "//lh3.googleusercontent.com/-oPQKa7ZQ87U/AAAAAAAAAAI/AAAAAAAABPk/tTZ21OI6_LY/s50-c-k-no/photo.jpg",
            "userId": "104428058049649798597"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "episodes = 1000\n",
        "rewards = []\n",
        "max_steps = 99\n",
        "\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()  # Assuming you already have env created as above\n",
        "    total_rewards = 0\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "        action = env.action_space.sample()  # TODO your policy here!\n",
        "        state, reward, done, info = env.step(env.action_space.sample())\n",
        "        total_rewards += reward\n",
        "        if done:\n",
        "            break\n",
        "    rewards.append(total_rewards)        \n",
        "\n",
        "print('Average score over time:', sum(rewards) / episodes)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average score over time: -388.476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K7OyY7XNiPmB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fe115e47-79c1-4fa6-c449-4ce0f6c66cbe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531517292142,
          "user_tz": 0,
          "elapsed": 498,
          "user": {
            "displayName": "Cassidy",
            "photoUrl": "//lh3.googleusercontent.com/-oPQKa7ZQ87U/AAAAAAAAAAI/AAAAAAAABPk/tTZ21OI6_LY/s50-c-k-no/photo.jpg",
            "userId": "104428058049649798597"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 100\n",
        "\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    \n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        action = np.argmax(qtable[state])\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 12.67\n",
            "Average penalties per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lHlQVyAIPNti",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8363727e-19f8-4a58-cce4-ac5ede64b364",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531517408342,
          "user_tz": 0,
          "elapsed": 1310,
          "user": {
            "displayName": "Cassidy",
            "photoUrl": "//lh3.googleusercontent.com/-oPQKa7ZQ87U/AAAAAAAAAAI/AAAAAAAABPk/tTZ21OI6_LY/s50-c-k-no/photo.jpg",
            "userId": "104428058049649798597"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for episode in range(total_episodes):\n",
        "    state = env.reset()  # Assuming you already have env created as above\n",
        "    total_rewards = 0\n",
        "    \n",
        "    \n",
        "    \n",
        "for step in range(max_steps):\n",
        "    action = env.action_space.sample()  # TODO your policy here!\n",
        "    state, reward, done, info = env.step(env.action_space.sample())\n",
        "    total_rewards += reward\n",
        "    if done:\n",
        "        break\n",
        "    rewards.append(total_rewards) \n",
        "    \n",
        "\n",
        "print('Average score over time:', sum(rewards) / total_episodes)\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average score over time: -4.07341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qm1MA2seLZyQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "total_episodes = 100000       \n",
        "learning_rate = 0.8          \n",
        "max_steps = 90              \n",
        "gamma = 0.65                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fCwUt7k6PJ9w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# more parameters\n",
        "epsilon = 1.0                 \n",
        "max_epsilon = 1.0           \n",
        "min_epsilon = 0.01            \n",
        "decay_rate = 0.1      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u0epVBUyL6Qy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "d631bcc1-18e8-4fae-e127-341de9e255cd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531517458337,
          "user_tz": 0,
          "elapsed": 28842,
          "user": {
            "displayName": "Cassidy",
            "photoUrl": "//lh3.googleusercontent.com/-oPQKa7ZQ87U/AAAAAAAAAAI/AAAAAAAABPk/tTZ21OI6_LY/s50-c-k-no/photo.jpg",
            "userId": "104428058049649798597"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "rewards = []\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "        \n",
        "        exp_exp_tradeoff = random.uniform(0, 1)\n",
        "        \n",
        "        ## take the biggest Q value \n",
        "        if exp_exp_tradeoff > epsilon:\n",
        "            action = np.argmax(qtable[state,:])\n",
        "\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "            \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "\n",
        "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
        "        \n",
        "        total_rewards += reward\n",
        "     \n",
        "        state = new_state\n",
        "      \n",
        "        if done == True: \n",
        "            break\n",
        "        \n",
        "    episode += 1\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
        "    rewards.append(total_rewards)\n",
        "\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\n",
        "print(qtable)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score over time: 7.93597\n",
            "[[ 0.          0.          0.          0.          0.          0.        ]\n",
            " [-1.61442809 -0.94527405 -1.61442809 -0.94527398  0.08419388 -9.94527398]\n",
            " [ 0.08419388  1.66799058  0.08383723  1.66799058  4.10460089 -7.33200942]\n",
            " ...\n",
            " [ 0.19433019  7.85323214  1.40936357 -0.48514314 -5.35370866 -4.27966987]\n",
            " [-1.98648731 -0.94527398 -1.9808819  -1.87723749 -5.06873522 -9.72298356]\n",
            " [ 9.97036907 12.131396    9.25596492 36.14285714  2.25954058  2.43608255]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}